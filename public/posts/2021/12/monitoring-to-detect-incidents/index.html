<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=author content="Hassen Harzallah "><meta name=description content="Recently, I have worked with a team developing a Spring Boot application. The application is deployed as a Java container in AWS and the logs are stored in Cloudwatch. The application was put behind an Nginx reverse proxy and Nginx logs are also stored in Cloudwatch. Every thing was going fine until they started adding new features that caused very high response times on the prod. Problems become more and more recurrent, developers were exhausted dealing with all this headache and users were very unsatisfied."><meta name=keywords content=",monitoring,elasticsearch"><meta name=robots content="noodp"><meta name=theme-color content><link rel=canonical href=https://hhassen.github.io/posts/2021/12/monitoring-to-detect-incidents/><title>Monitoring to detect incidents :: Hassen Harzallah</title><link href=https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css rel=stylesheet type=text/css><link rel=stylesheet href=../../../../main.dede02da9537a98158079c023e83573e18127834838ef08172acce888341a797.css><meta itemprop=name content="Monitoring to detect incidents"><meta itemprop=description content="Recently, I have worked with a team developing a Spring Boot application. The application is deployed as a Java container in AWS and the logs are stored in Cloudwatch. The application was put behind an Nginx reverse proxy and Nginx logs are also stored in Cloudwatch. Every thing was going fine until they started adding new features that caused very high response times on the prod. Problems become more and more recurrent, developers were exhausted dealing with all this headache and users were very unsatisfied."><meta itemprop=datePublished content="2021-12-29T10:10:23+02:00"><meta itemprop=dateModified content="2021-12-29T10:10:23+02:00"><meta itemprop=wordCount content="528"><meta itemprop=keywords content="monitoring,elasticsearch,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Monitoring to detect incidents"><meta name=twitter:description content="Recently, I have worked with a team developing a Spring Boot application. The application is deployed as a Java container in AWS and the logs are stored in Cloudwatch. The application was put behind an Nginx reverse proxy and Nginx logs are also stored in Cloudwatch. Every thing was going fine until they started adding new features that caused very high response times on the prod. Problems become more and more recurrent, developers were exhausted dealing with all this headache and users were very unsatisfied."><meta property="article:published_time" content="2021-12-29 10:10:23 +0200 +0200"></head><body><div class=container><header class=header><span class=header__inner><a href=../../../../ style=text-decoration:none><div class=logo><span class=logo__mark>></span>
<span class=logo__text>$ cd ~</span>
<span class=logo__cursor></span></div></a><span class=header__right><nav class=menu><ul class=menu__inner><li><a href=https://hhassen.github.io/about>About</a></li><li><a href=https://hhassen.github.io/posts>Blog</a></li><li><a href=https://hhassen.github.io/tags>Tags</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span><span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41c10.4934.0 19-8.5066 19-19C41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><main class=post><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>3 minutes</p></div><article><h1 class=post-title><a href=https://hhassen.github.io/posts/2021/12/monitoring-to-detect-incidents/>Monitoring to detect incidents</a></h1><div class=post-content><p>Recently, I have worked with a team developing a Spring Boot application. The application is deployed as a Java container in AWS and the logs are stored in Cloudwatch.
The application was put behind an Nginx reverse proxy and Nginx logs are also stored in Cloudwatch.
<img src=https://raw.githubusercontent.com/hhassen/hhassen.github.io_source/master/resources/_gen/images/architecture.png alt="application architecture"></p><p>Every thing was going fine until they started adding new features that caused very high response times on the prod. Problems become more and more recurrent, developers were exhausted dealing with all this headache and users were very unsatisfied.</p><p>I tried to help this team and the first step was to see what is going on. I found out that even developers struggle to get the real cause of problems and they often have to pass hours reading thousands of line of logs in Cloudwatch and the fixes they made were usually temporary.</p><p>For me, there was missing a crucial element for the functioning of any development team : monitoring. We had a lot of data in our possession but nothing was done to get useful information from that.</p><p>Thus, I decided to implement a monitoring solution using <code>Elasticsearch</code> and <code>Kibana</code>. First, I worked on sending all the information from Cloudwatch logs to Elasticsearch. I used <code>Filebeat</code> with the following input module : <code>AWS Cloudwatch Input</code> (<a href=https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-aws-cloudwatch.html)>https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-aws-cloudwatch.html)</a>. This module calls AWS API regularly to get new lines of logs.</p><p>In addition, I found out that an Actuator endpoint was available and developers use it to expose application metrics using <code>Prometheus</code> format. I used <code>Metricbeat</code> to scrap those metrics and send them to Elasticsearch (<a href=https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-module-prometheus.html)>https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-module-prometheus.html)</a>.</p><p>After ingesting and filtering data using <code>Logstash</code> and storing them in <code>Elasticsearch</code>, came the rewarding part of creating visualitions and dashboard in <code>Kibana</code>.</p><p>I have made out 2 different types of Dashboards:</p><h3 id=nginx-dashboard-user-experience-metrics>Nginx dashboard: user experience metrics</h3><p>This dashboard contains metrics about the user experience : number of requests, 500 errors, response time, visitors per day, OS, most visited URLs&mldr;
<img src=https://raw.githubusercontent.com/hhassen/hhassen.github.io_source/master/resources/_gen/images/nginx_dashboard.png alt="nginx dashboard"></p><h3 id=prometheus-dashboard-application-metrics>Prometheus dashboard: application metrics</h3><p>This dashboard contains metrics about the java application : methods execution time, http requests, JVM metric, 500 errors by URL and by Stacktrace&mldr;
<img src=https://raw.githubusercontent.com/hhassen/hhassen.github.io_source/master/resources/_gen/images/prometheus_jvm.png alt="prometheus dashboard">
<img src=https://raw.githubusercontent.com/hhassen/hhassen.github.io_source/master/resources/_gen/images/prometheus_500.png alt="prometheus 500 errors dashboard"></p><h3 id=realcase-situation-of-detecting-an-incident>Realcase situation of detecting an incident</h3><p>Using this monitoring tool, I went back to a recent incident in Production and I tried to detect it just using the metrics I have.</p><p>Response time:
<img src=https://raw.githubusercontent.com/hhassen/hhassen.github.io_source/master/resources/_gen/images/response_time_incident.png alt="incident detection response time">
Response time by HTTP path:
<img src=https://raw.githubusercontent.com/hhassen/hhassen.github.io_source/master/resources/_gen/images/response_time_http_incident.png alt="incident detection response time by http path">
Execution time of java methods:
<img src=https://raw.githubusercontent.com/hhassen/hhassen.github.io_source/master/resources/_gen/images/response_time_methods_incident.png alt="incident detection execution time of methods"></p><p>As I plotted the response time for that particular period, and guess what !! They went really up. I have also found out the following information:</p><ul><li><strong>Response time</strong> was already <strong>increasing</strong> for several days due to increasing number of users.</li><li>The business team <strong>reported the problem</strong> 1 day after incident.</li><li><strong>Developers were stuck</strong> for days not knowing were all of this came. They were manually <strong>reading logs</strong> in Cloudwatch.</li><li>A <strong>DB upsize</strong> was done 2 days after the incident was revealed and it helped improving situation.</li><li>A <strong>hotfix</strong> deliverd 4 days after the incident has been effective solving the problem.</li></ul><p>As we can see the monitoring solution does effectively help detect and even anticipate problems, as well as measuring the impact of adopted measures.</p><p>Now, with the information we have, we finally have <strong>happy developers and satisfied users</strong>.</p></div></article><hr><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=tag><a href=https://hhassen.github.io/tags/monitoring>monitoring</a></span><span class=tag><a href=https://hhassen.github.io/tags/elasticsearch>elasticsearch</a></span></p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>528 Words</p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>2021-12-29 08:10 +0000</p></div><div class=pagination><div class=pagination__title><span class=pagination__title-h></span><hr></div><div class=pagination__buttons><span class="button previous"><a href=https://hhassen.github.io/posts/2025/09/my-bitcoins-almost-disappeared-forever-fixing-a-crashing-blockstream-green-lightning-wallet/><span class=button__icon>←</span>
<span class=button__text>My Bitcoins almost disappeared forever: Fixing a Crashing Blockstream Green Lightning Wallet</span></a></span>
<span class="button next"><a href=https://hhassen.github.io/posts/2020/06/kubernetes-project-deploy-a-sentiment-analysis-application/><span class=button__text>Kubernetes project: deploy a Sentiment Analysis application</span>
<span class=button__icon>→</span></a></span></div></div></main></div><footer class=footer><div class=footer__inner><div class=footer__content><span>&copy; 2025</span>
<span><a href=https://hhassen.github.io/>Hassen Harzallah</a></span>
<span><a href=https://hhassen.github.io/posts/index.xml target=_blank title=rss><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></span></div></div><div class=footer__inner><div class=footer__content><span>Powered by <a href=http://gohugo.io>Hugo</a></span>
<span>Made with &#10084; by <a href=https://github.com/rhazdon>Djordje Atlialp</a></span></div></div></footer></div><script type=text/javascript src=../../../../bundle.min.8cc3758efe48ef82e2eb9a5f317b44c0805353a43762207be6fe8ffb05815cce7a19d37f6bf387c378a3bdfc3029981668d645374a33db4ee3480e15a4bfdc7c.js integrity="sha512-jMN1jv5I74Li65pfMXtEwIBTU6Q3YiB75v6P+wWBXM56GdN/a/OHw3ijvfwwKZgWaNZFN0oz207jSA4VpL/cfA=="></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-143758672-1","auto"),ga("send","pageview"))</script></body></html>